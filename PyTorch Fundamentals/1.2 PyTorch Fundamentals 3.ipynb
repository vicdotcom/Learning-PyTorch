{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9009f4a",
   "metadata": {},
   "source": [
    "## PyTorch Fundamentals 3\n",
    "### Reproducibility\n",
    "- Entails trying to take the random out of random to ensure the experiment and results can be replicated.\n",
    "- In short, it's how a neural network learns\n",
    "   - Start with random numbers\n",
    "   - Tensor operations\n",
    "   - Update random numbers to try and make them of the data\n",
    "   - Repeat\n",
    "- To reduce randomness in neural networks, comes the concept of **random seed**. What it does is *flavours* the randomness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578605d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da68f01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([[0.3800, 0.7958, 0.9141, 0.2762],\n",
      "        [0.3013, 0.9508, 0.2706, 0.3371],\n",
      "        [0.3863, 0.2972, 0.3110, 0.6848]])\n",
      "B: tensor([[0.2747, 0.3186, 0.7778, 0.4929],\n",
      "        [0.2139, 0.2583, 0.8954, 0.0457],\n",
      "        [0.1885, 0.2728, 0.8619, 0.0564]])\n",
      "\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "## Create two random tensors\n",
    "random_A= torch.rand(3,4)\n",
    "random_B= torch.rand(3,4)\n",
    "\n",
    "print('A:', random_A)\n",
    "print('B:', random_B)\n",
    "print('\\n',random_A == random_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4bb900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "D: tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      " tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "## Random Tensors with seed\n",
    "random_seed= 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "random_C= torch.rand(3,4)\n",
    " # Note that random seed function needs to be run every time a random tensor is contructed\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "random_D= torch.rand(3,4)\n",
    "\n",
    "print('C:', random_C)\n",
    "print('D:', random_D)\n",
    "print('\\n', random_C==random_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a35376",
   "metadata": {},
   "source": [
    "### Accessing a GPU\n",
    "- GPUs/TPUs can enable faster Tensor computations.\n",
    "- Provided primarily by NVIDIA's CUDA toolkit or from Google (Colab). PyTorch can work with either for faster operations\n",
    "- Getting a GPU\n",
    "   - Google Colab pro (not free)\n",
    "   - Set up and use your own GPU (can be technical to set up and costly to purchase the GPU and other hardware required)\n",
    "   - Use cloud computing platforms (AWS, GCP, Azure)\n",
    "\n",
    "*For 2 and 3 refer to PyTorch setup documentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6502fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "## Run the below code once connected to the GPU/TPU to check specifications\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75067fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for GPU access wth PyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5118bee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set up device agnostic code\n",
    "# In the event PyTorch disconnects from CUDA\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0240b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count no. of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe3f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5472, 0.0062],\n",
       "         [0.9516, 0.0753]]),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using the GPU\n",
    "## Putting the tensors and models on the set device\n",
    " # GPU for faster computation, CPU if that is the only option available\n",
    "tensor= torch.rand(2,2)\n",
    "tensor_on_device= tensor.to(device)\n",
    "tensor_on_device, tensor_on_device.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413fb779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.54719156, 0.00616044],\n",
       "        [0.95155454, 0.07526588]], dtype=float32),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note that if the tensor is on a GPU. You cannot convert it to a Numpy array\n",
    "## To avoid an eror convert the Tensor to run on CPU\n",
    "tensor_cpu= tensor_on_device.cpu().numpy()\n",
    "tensor_cpu, type(tensor_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c508d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
