{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c57242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f89828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20]),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z= torch.arange(20)\n",
    "\n",
    "z.shape, z\n",
    " # Vector shape (1 dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997ed1d",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3cb1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 20]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "          18, 19]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add an extra column dimension\n",
    " # The below code shows we want to shape a tensor from a 1D vector to a 2D matrix\n",
    " # The matrix should have 1 row and 'n' columns\n",
    " # 'n' depends on the length of the 1D matrix, otherwise, reshaping will bring an error\n",
    "z_reshaped= z.reshape(1, len(z))\n",
    " \n",
    "z_reshaped.shape, z_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49526ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 1]),\n",
       " tensor([[ 0],\n",
       "         [ 1],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7],\n",
       "         [ 8],\n",
       "         [ 9],\n",
       "         [10],\n",
       "         [11],\n",
       "         [12],\n",
       "         [13],\n",
       "         [14],\n",
       "         [15],\n",
       "         [16],\n",
       "         [17],\n",
       "         [18],\n",
       "         [19]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add extra row dimensions\n",
    " # The rule of 'n' still applies\n",
    "z_reshaped_row= z.reshape(len(z), 1)\n",
    "z_reshaped_row.shape, z_reshaped_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c7e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]])\n",
      "\n",
      "torch.Size([10, 2])\n",
      "tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [16, 17],\n",
      "        [18, 19]])\n"
     ]
    }
   ],
   "source": [
    "## Basically, the new reshaped tensor should be able to hold the....\n",
    "## ...same no. of elements as the original tensor\n",
    "z_shaped= z.reshape(4,5)\n",
    "z_shaped1= z.reshape(10,2)\n",
    "print(z_shaped.shape)\n",
    "print(z_shaped)\n",
    "print()\n",
    "print(z_shaped1.shape)\n",
    "print(z_shaped1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e316c3",
   "metadata": {},
   "source": [
    "#### Change View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0052f1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f29f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 5]),\n",
       " tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Changing the view\n",
    "v= z.view(4,5)\n",
    "v.shape, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d353e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,   1,   2,   3,   4],\n",
       "         [  5,   6,   7, 300,   9],\n",
       "         [ 10,  11,  12,  13,  14],\n",
       "         [ 15,  16,  17,  18,  19]]),\n",
       " tensor([  0,   1,   2,   3,   4,   5,   6,   7, 300,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Changing the viewing tensor 'v' also changes the orignal tensor z\n",
    "## This is because the view of a tensor shares the same memory as the original tensor\n",
    "## Here we change the element on the first row of the third column\n",
    "v[1,3]= 300\n",
    "v, z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c4627",
   "metadata": {},
   "source": [
    "#### Stack Tensors on top of each other\n",
    "Concatenate tensors along a new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b97c094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20]),\n",
       " tensor([  0,   1,   2,   3,   4,   5,   6,   7, 300,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9820110b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 20]),\n",
       " tensor([[  0,   1,   2,   3,   4,   5,   6,   7, 300,   9,  10,  11,  12,  13,\n",
       "           14,  15,  16,  17,  18,  19],\n",
       "         [  0,   1,   2,   3,   4,   5,   6,   7, 300,   9,  10,  11,  12,  13,\n",
       "           14,  15,  16,  17,  18,  19]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_stacked= torch.stack([z, z])\n",
    "z_stacked.shape, z_stacked\n",
    " # The individual vector tensors are stacked on top of each other to create a mattrix tensor\n",
    " # New (row) dimension is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f86fed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 2]),\n",
       " tensor([[  0,   0],\n",
       "         [  1,   1],\n",
       "         [  2,   2],\n",
       "         [  3,   3],\n",
       "         [  4,   4],\n",
       "         [  5,   5],\n",
       "         [  6,   6],\n",
       "         [  7,   7],\n",
       "         [300, 300],\n",
       "         [  9,   9],\n",
       "         [ 10,  10],\n",
       "         [ 11,  11],\n",
       "         [ 12,  12],\n",
       "         [ 13,  13],\n",
       "         [ 14,  14],\n",
       "         [ 15,  15],\n",
       "         [ 16,  16],\n",
       "         [ 17,  17],\n",
       "         [ 18,  18],\n",
       "         [ 19,  19]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can specify a target dimension we want the stacked tensor to appear in\n",
    " # Default is dim= 0 (row stacking)\n",
    " # dim= 1 peforms column stacking\n",
    "z_stacked1= torch.stack([z,z], dim= 1)\n",
    "z_stacked1.shape, z_stacked1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc3440f",
   "metadata": {},
   "source": [
    "#### Squeezing\n",
    "Removes all dimensions of size 1 from the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c836ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor and tensor shape\n",
      "torch.Size([1, 15]) tensor([[0.2277, 0.0444, 0.0472, 0.4922, 0.8394, 0.9535, 0.5476, 0.2051, 0.5645,\n",
      "         0.3095, 0.4114, 0.0684, 0.0987, 0.7165, 0.4741]])\n",
      "\n",
      "Squeezed tensor and tensor shape\n",
      "torch.Size([15]) tensor([0.2277, 0.0444, 0.0472, 0.4922, 0.8394, 0.9535, 0.5476, 0.2051, 0.5645,\n",
      "        0.3095, 0.4114, 0.0684, 0.0987, 0.7165, 0.4741])\n"
     ]
    }
   ],
   "source": [
    "## Original tensor\n",
    "s= torch.rand([1,15])\n",
    "print('Original tensor and tensor shape')\n",
    "print(s.shape, s)\n",
    "print('\\nSqueezed tensor and tensor shape')\n",
    "print(s.squeeze().shape, s.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97a071f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape\n",
      "torch.Size([4, 5, 1, 3, 1])\n",
      "\n",
      "Squeezed tensor shape\n",
      "torch.Size([4, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "s1= torch.rand([4, 5, 1, 3, 1])\n",
    " # 5 dimensional tensor\n",
    "print('Original tensor shape')\n",
    "print(s1.shape)\n",
    "print('\\nSqueezed tensor shape')\n",
    "print(s1.squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5482f010",
   "metadata": {},
   "source": [
    "#### Unsqueeze\n",
    "Adds a dimension of size 1 to the tensor's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8183ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor shape\n",
      "torch.Size([4, 5, 3])\n",
      "\n",
      "New tesnor shape (dim= 0)\n",
      "torch.Size([1, 4, 5, 3])\n",
      "\n",
      "Unsqueezed tensor shape (dim= 1)\n",
      "torch.Size([4, 1, 5, 3])\n",
      "\n",
      "Unsqueezed tensor shape (dim= 1)\n",
      "torch.Size([4, 1, 5, 3])\n",
      "\n",
      "Unsqueezed tensor shape (dim= 3)\n",
      "torch.Size([4, 5, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "s_squeezed= s1.squeeze()\n",
    "print('Original Tensor shape')\n",
    "print(s_squeezed.shape)\n",
    "\n",
    "print('\\nNew tesnor shape (dim= 0)')\n",
    "print(s_squeezed.unsqueeze(dim= 0).shape)\n",
    "\n",
    "print('\\nUnsqueezed tensor shape (dim= 1)')\n",
    "print(s_squeezed.unsqueeze(dim= 1).shape)\n",
    "\n",
    "print('\\nUnsqueezed tensor shape (dim= 1)')\n",
    "print(s_squeezed.unsqueeze(dim= 1).shape)\n",
    "\n",
    "print('\\nUnsqueezed tensor shape (dim= 3)')\n",
    "print(s_squeezed.unsqueeze(dim= 3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8815b5b",
   "metadata": {},
   "source": [
    "#### Permute\n",
    "- Can be used to change (swap) the order of the dimensions of a tensor.\n",
    "- Common when working with image tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23df73bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape torch.Size([220, 221, 3])\n",
      "New shape: torch.Size([3, 220, 221])\n",
      "\n",
      "Checking whether changes are made\n",
      "Original: 0.025391995906829834\n",
      "Permuted: 0.27365535497665405\n"
     ]
    }
   ],
   "source": [
    "## We create an image tensor [height, width, color channels]\n",
    "p= torch.rand([220, 221, 3])\n",
    "p_permuted= p.permute(2, # dim 2 is mapped/swapped to the first index\n",
    "                      0, # dim 0 is swapped to the 2nd index\n",
    "                      1) # dim 1 is swapped to the last/3rd index\n",
    "\n",
    "print(f'Previous shape {p.shape}')\n",
    "print(f'New shape: {p_permuted.shape}')\n",
    "\n",
    "print('\\nChecking whether changes are made')\n",
    "print(f'Original: {p[0,0,2]}') # Row 0, column 0, matrix 2\n",
    "print(f'Permuted: {p_permuted[0,0,2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b665c3e",
   "metadata": {},
   "source": [
    "### Indexing (Selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2520fc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3, 3]' is invalid for input of size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tensor\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m tensor\u001b[38;5;241m.\u001b[39mshape, tensor\n\u001b[0;32m      3\u001b[0m  \u001b[38;5;66;03m# Tensor shape is 1 matrix, 3 rows, 3 columns\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 3, 3]' is invalid for input of size 19"
     ]
    }
   ],
   "source": [
    "tensor= torch.arange(1,20).reshape(1, 3, 3)\n",
    "tensor.shape, tensor\n",
    " # Tensor shape is 1 matrix, 3 rows, 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d98715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5), tensor(5))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2nd value on the middle bracket\n",
    "tensor[0, 1, 1], tensor[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5347db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Last value of the last bracket\n",
    "tensor[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b93b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The entire first row\n",
    "tensor[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8bc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 7])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The entire first column\n",
    "tensor[0,:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f8bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The second and third row\n",
    "tensor[0, 1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63065a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The entire last column\n",
    "tensor[0,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64751db8",
   "metadata": {},
   "source": [
    "### PyTorch Tensors & NumPy\n",
    "NumPy is a popular scientific numerical computing library. Because of this, PyTorch has the functionality to interact with it.\n",
    "- If the data is in NumPy and we want it in PyTorch -> `torch.from_numpy(array_data)`\n",
    "- If the data is in PyTorch and we want it in NumPy -> `torch.Tensor.numpy(tensor_data)`\n",
    "\n",
    "They dont share memory meaning changing one will not change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b97484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array\n",
      "[[0.2376379  0.22782564 0.69813364]\n",
      " [0.26976439 0.928965   0.94240912]\n",
      " [0.23268163 0.94963518 0.93065838]]\n",
      "\n",
      "Tensor\n",
      "tensor([[0.2376, 0.2278, 0.6981],\n",
      "        [0.2698, 0.9290, 0.9424],\n",
      "        [0.2327, 0.9496, 0.9307]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## NumPy array to tensor\n",
    "array= np.random.random([3,3])\n",
    "print('Array')\n",
    "print(array)\n",
    "\n",
    "tensor= torch.from_numpy(array)\n",
    "print('\\nTensor')\n",
    "print(tensor)\n",
    " # Datatype of the converted tensor is float64 as is the default datatype for NumPy arrays\n",
    " # Default datatype for PyTorch tensors is float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384db4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor\n",
      "tensor([[0.2376, 0.2278, 0.6981],\n",
      "        [0.2698, 0.9290, 0.9424],\n",
      "        [0.2327, 0.9496, 0.9307]], dtype=torch.float64)\n",
      "\n",
      "Array\n",
      "[[0.2376379  0.22782564 0.69813364]\n",
      " [0.26976439 0.928965   0.94240912]\n",
      " [0.23268163 0.94963518 0.93065838]]\n"
     ]
    }
   ],
   "source": [
    "## Tensor to NumPy array\n",
    "print('Tensor')\n",
    "print(tensor)\n",
    "\n",
    "print('\\nArray')\n",
    "print(torch.Tensor.numpy(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be61a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
